## About Me

<p align="justify">
I am passionate about leveraging artificial intelligence to drive innovation and make AI accessible to all. With a strong background in data analysis and a drive for continuous improvement, I aim to contribute to technological advancements and ethical AI development.
</p>

## Education

- **MSc in Applied Data Analytics** - Boston University, Massachusetts (January 2025)


## Professional Experience

### AI/ML Engineer at Steradian, Bhubaneswar
*(June 2022- July 2023)*
- Enhanced data quality for medical datasets, improving accuracy and reliability.
- Optimized IoT data analysis, leading to a 30% increase in operational efficiency.
- Developed a machine learning-based recommendation engine, boosting cross-selling by 40%.

### Research and Development Engineer at Innotrat, Remote
*(November 2022- August 2023)*
- Built a document classification system using BERT and Generative AI, categorizing files with improved precision.
- Performed object detection on drawings with YOLOv5OBB, achieving mAP >85% across 200+ labeled drawings.
- Trained an OCR model using PaddleOCR to recognize handwritten text, achieving an hmean/F1 score >90%.

### Data Analyst Intern at Remotecare, Chennai
*(August 2021- June 2022)*
- Implemented ML models for customer churn prediction and sales forecasting.
- Conducted extensive data analysis to identify trends and drive company performance.

## üöÄ Skills

### üõ†Ô∏è Programming Languages & Tools  
- **Languages:** Python, SQL, R, PySpark, MATLAB, Bash, C, HTML, CSS  
- **Libraries & Frameworks:** Pandas, NumPy, Scikit-Learn, TensorFlow, Keras, PyTorch, NLTK, Spacy, OpenCV  

### üìä Data Engineering  
- **ETL & Data Pipelines:** Apache Spark, Airflow, dbt, Kafka, Luigi  
- **Data Warehousing & Storage:** AWS Glue, Redshift, S3, EMR, Snowflake, Google BigQuery, Azure Synapse  
- **Big Data Technologies:** Hadoop, Apache Spark, Data Lakes, Delta Lake  
- **Version Control & CI/CD:** Git, GitHub Actions, Docker, Kubernetes, Terraform  

### ü§ñ Machine Learning & AI  
- **Traditional ML:** Regression, Classification, Clustering, Random Forest, Gradient Boosting, SVM  
- **Deep Learning:** CNNs, GANs, LSTMs, Transformer Models (BERT, GPT), Reinforcement Learning  
- **Feature Engineering & Model Optimization:** Hyperparameter Tuning, Cross-Validation, Model Explainability  

### üìà Data Analysis & Visualization  
- **Exploratory Data Analysis (EDA):** Pandas, NumPy, Scipy, Statsmodels  
- **Data Visualization:** Matplotlib, Seaborn, Power BI, Tableau  
- **Statistical Analysis:** Probability, Hypothesis Testing, A/B Testing  

### ‚öôÔ∏è MLOps & DevOps  
- **Cloud Platforms:** AWS, GCP, Azure  
- **Model Deployment:** Flask, FastAPI, TensorFlow Serving, MLflow, Vertex AI, Sagemaker  
- **CI/CD & Automation:** Jenkins, Docker, Kubernetes, Airflow, Terraform  

### üèÜ Soft Skills  
- **Problem-Solving | Critical Thinking | Effective Communication | Team Collaboration | Agile Methodologies**  


## Featured Work

Below are some of the projects I'm most proud of. Each showcases my technical skills and commitment to solving complex problems and delivering real value through data-driven innovation.

# üìå AWS Serverless Data Pipeline

## üöÄ Project Overview  
This project demonstrates a serverless data pipeline using AWS S3, SNS, SQS, Lambda, Glue, and Athena to automate cross-region data migration and querying. The pipeline transfers data from an S3 bucket in one region to another, automates schema detection with Glue, and enables querying with Athena.

### ‚úÖ Key Learning Outcomes:
- Migrate data across **S3 buckets** using **SNS, SQS, and Lambda**.
- Automate workflows with **AWS Lambda** for event-driven processing.
- Catalog data in **AWS Glue** and query it via **AWS Athena**.
- Implement **cross-region data management** with **serverless architectures**.
- Build a **scalable and automated data processing pipeline** in AWS.

## üîß Project Steps
1. **Create S3 Buckets** ‚Äì Set up source and target buckets for data transfer.  
2. **Configure SNS & SQS** ‚Äì Set up notifications and event-driven triggers.  
3. **Develop Lambda Function** ‚Äì Automate data transfer and trigger Glue Crawler.  
4. **Run Glue Crawler** ‚Äì Detect schema and register data in the **Glue Catalog**.  
5. **Query Data in Athena** ‚Äì Use **SQL queries** to analyze the transferred data.

This project provides hands-on experience in **cloud automation, serverless workflows, and scalable data processing**. üöÄ


### LLM-Powered Wikipedia Chat Assistant with RAG
- Developed a sophisticated conversational assistant empowered by cutting-edge LLM technologies and retrieval-based augmentation techniques.
- Implemented the ReAct prompt framework to guide the assistant in structured question answering, ensuring accurate and informative responses.
- Leveraged OpenAI's LLM frameworks along with Llamaindex and Chainlit for seamless integration of Wikipedia knowledge into the conversational flow.
- Ensured user-friendly interaction by enabling users to ask questions and receive well-informed answers based on selected Wikipedia pages.
- Employed advanced retrieval mechanisms and context-awareness to enhance response coherence and relevance, providing an enriched conversational experience.

### Object Detection Using YOLOV8
- Developed a robust web application leveraging YOLOv8 for real-time object detection in videos.
- Implemented an intuitive user interface using Streamlit, enabling seamless interaction and analysis of uploaded content.
- Integrated OpenCV for efficient image processing and accurate object detection functionalities.
- Customized features such as class selection and bounding box visualization enhance user experience and facilitate precise analysis of detected objects.
- Ensured scalability and flexibility for future enhancements by following best practices in coding and project organization.

### Chatbot with OpenAI GPT-3 using Flask
- Developed a chatbot application utilizing Flask and integrated the powerful GPT-3 API for generating human-like responses to user queries.
- Implemented features to maintain a comprehensive history of all user interactions with the GPT-3 API, ensuring transparency and traceability.
- Leveraged the immense capabilities of GPT-3, trained on vast amounts of text data, to produce responses indistinguishable from human-written text.
- Ensured seamless integration of the GPT-3 API into the Flask-based chatbot, providing users with a natural and engaging conversational experience.
- Successfully deployed the chatbot application, empowering users to interact with a sophisticated AI-powered assistant capable of providing high-quality responses to a wide range of queries.

### Automatic Speech Recognition With TensorFlow
- Developed an end-to-end deep learning project focusing on audio data processing and visualization, leveraging TensorFlow and Python.
- Implemented audio processing techniques and spectrogram calculation to preprocess and analyze audio data effectively.
- Evaluated the model's performance using the Word Error Rate (WER) metric, ensuring accuracy and reliability of the final AI model.
- Successfully deployed the trained AI model, providing a practical solution for audio data analysis and processing tasks.
- Acquired valuable insights and hands-on experience in building real-world deep learning models for audio data applications through this comprehensive project.

### Conversational Assistant Using Rasa
- Developed a chatbot using Rasa, an open-source machine learning framework, by incorporating training data and visualizing chatbot stories for effective model training.
- Generated training data through various methods, including creating files with messages and actions, as well as interactive chatting with the bot to label messages and actions.
- Utilized Flask to build a simple application and seamlessly connected it with the chatbot backend, enabling smooth interaction and integration.
- Gained practical experience in chatbot development, from data generation and model training to application deployment, through hands-on implementation of Rasa framework and Flask integration.
- Demonstrated proficiency in leveraging machine learning frameworks and web development technologies to create functional and interactive chatbot applications, contributing to a holistic understanding of AI-powered conversational agents.

### Build a Road Sign Recognition System with CNN
- Extensive data collection: Acquired diverse dataset with various road signs, encompassing different lighting conditions, perspectives, and environmental settings.
- Utilization of specialized deep learning architecture: Employed Convolutional Neural Networks (CNNs) as the core technological foundation for image recognition tasks.
- Implementation of Python-based libraries: Leveraged TensorFlow to develop a robust road sign classification system.
- Significant advancement in road safety: This project marks a pivotal step towards enhancing road safety and advancing the capabilities of autonomous vehicles and traffic management systems.
- Contribution to automation: By automating the identification of road signs, the project aims to improve efficiency and accuracy in traffic management.

### The Learning Agency Lab - PII Data Detection
- Spearheaded the development of a cutting-edge solution for the Kaggle competition aimed at automating the detection and removal of personally identifiable information (PII) from student writing.
- Orchestrated meticulous data preprocessing to standardize and refine the textual data, ensuring optimal performance of subsequent algorithms.
- Leveraged advanced techniques such as Named Entity Recognition (NER) and machine learning models to accurately identify and categorize PII entities within the text.
- Implemented robust rule-based filtering and pattern matching algorithms to effectively remove sensitive information while preserving the integrity and coherence of the educational content.
- Demonstrated exceptional proficiency in testing, refining, and fine-tuning the developed solution, resulting in a high-performing system poised to make a significant impact in the realms of privacy protection and educational data utilization.

## Additional Information

If you're interested in the more detailed aspects of my work or want to see my code in action, check out the repositories below. Each repository includes extensive documentation on how the projects were built and how they can be run.

- [AirBnB Destination Prediction](https://github.com/shradhanjalipradhan/AirBnB)
- [Self-Driving Car Simulation](https://github.com/shradhanjalipradhan/Self-Driving-Car)
- [Quora Question Pairs Analysis](https://github.com/shradhanjalipradhan/Quora-Question-Pairs)

I'm also open to feedback on my projects, so don't hesitate to raise an issue or submit a pull request!

Thank you for taking the time to explore my work. Let's connect and make something great together!

## How to Reach Me

I am always interested in hearing about new opportunities, collaborations, or just to chat about technology and AI. Feel free to reach out to me through the following channels:

- **Location:** United States
- **Email:** [edu.shradhanjali@gmail.com](mailto:edu.shradhanjali@gmail.com)
- **Twitter:** [@Shradha1405](https://twitter.com/Shradha1405)
- **LinkedIn:** [Shradhanjali Pradhan](https://www.linkedin.com/in/shradhanjalipradhan/)
- **Github:** [shradhanjalipradhan](https://github.com/shradhanjalipradhan)
- **Kaggle:** [shradhanjalipradhan](https://www.kaggle.com/shradhanjalipradhan)
- **Learning:** Currently deepening my understanding of Generative AI.
- **Collaboration:** Open to collaborating on AI content creation, technical writing, and AI project development.
